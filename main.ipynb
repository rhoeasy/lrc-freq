{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/过江寒.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/如词穷一般.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/迢迢.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/云何住.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/天上掉下个林妹妹.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/孽海记.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/青蛇.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/琴瑟在御.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/吹梦到西洲.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/一梦惊鸿.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/山上雪.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/青白.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/葬花词.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/人间不值得.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/楚歌起.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/四万秋.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/红白.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/红拂夜奔.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/雪落在先生肩上.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/心上诗.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/赴鸿门.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/玉簪记.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/清平误.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/望江亭.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/三过门.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/紫禁城里的似水流年.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/怜香伴.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/杨花落尽子规啼.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/九万字.txt\n",
      "read /Users/rhoneas/code/python/lrc-freq/lrcs.new/你是我年少时求剑刻的舟.txt\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "import os\n",
    "\n",
    "\n",
    "def is_all_chinese(strs):\n",
    "    \"\"\"\n",
    "    judge a sentence is or not Chinese\n",
    "    \"\"\"\n",
    "    for _char in strs:\n",
    "        if not '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "workdir = os.path.join(os.getcwd(), \"lrcs.new\")\n",
    "wordmap = dict()\n",
    "word_sentence_map = dict()\n",
    "\n",
    "for root, _, files in os.walk(workdir):\n",
    "    # traverse the files\n",
    "    for lrcfile in files:\n",
    "        curfile = os.path.join(root, lrcfile)\n",
    "        print(f\"read {curfile}\")\n",
    "        with open(curfile, \"r\", encoding=\"utf-8\") as filesrc:\n",
    "            # handle each line\n",
    "            for line in filesrc.readlines():\n",
    "                line = line.strip()\n",
    "                # split words into map\n",
    "                results = jieba.cut(line,cut_all=False,HMM=True)\n",
    "                # results are words\n",
    "                for result in results:\n",
    "                    if not is_all_chinese(result):\n",
    "                        break\n",
    "                    \n",
    "                    # count the occured times of each word\n",
    "                    if wordmap.get(result, 0) == 0:\n",
    "                        wordmap[result] = 1\n",
    "                    else:\n",
    "                        wordmap[result] += 1\n",
    "\n",
    "                    # record where the word come from\n",
    "                    source_counter = result + \"count\"\n",
    "                    if word_sentence_map.get(source_counter, 0) == 0:\n",
    "                        word_sentence_map[source_counter] = 1\n",
    "                    else:\n",
    "                        word_sentence_map[source_counter] += 1\n",
    "\n",
    "                    source_sentence = word_sentence_map.get(result,\" \")\n",
    "                    source_sentence += \"(\"+str(word_sentence_map.get(source_counter)) + \"):\"\n",
    "                    source_sentence += line\n",
    "                    source_sentence += \"<<\"+lrcfile.split(\".\")[0]+\">>\"\n",
    "                    source_sentence += \" \"\n",
    "                    source_sentence.strip()\n",
    "                    word_sentence_map[result] = source_sentence\n",
    "\n",
    "sorted_wordmap = sorted(wordmap.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "with open(os.path.join(os.getcwd(), \"lrcs.txt\"), \"w\") as resultfile:\n",
    "    for i, result in enumerate(sorted_wordmap):\n",
    "        source_sentence=word_sentence_map.get(result[0])\n",
    "        resultfile.write(f\"[{i+1}]:\\\"{result[0]}\\\",({result[1]})---{source_sentence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# handle the lrc format\n",
    "\n",
    "worklist = os.listdir(\"lrcs.raw\")\n",
    "for work in worklist:\n",
    "    fp = os.path.join(\"lrcs.raw\",work)\n",
    "    newfp = os.path.join(\"lrcs.new\",work)\n",
    "    with open(fp, \"r\", encoding=\"utf-8\") as fin, open(newfp,\"w\",encoding=\"utf-8\") as fout:\n",
    "        for line in fin.readlines():\n",
    "            if line != \"\\n\":\n",
    "                fout.write(line.replace(\" \", \"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
